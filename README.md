# ğŸ§ª LLM-Based Test Case Generation System

An AI-powered QA automation tool that converts functional requirements into structured test cases with edge case extraction, classification, coverage scoring, and export support.

This project demonstrates how Large Language Models (LLMs) can enhance **shift-left testing**, improve test coverage, and automate requirement-to-test workflows.

---

## ğŸš€ Features

### âœ… Core Capabilities
- Convert functional requirements â†’ structured test cases
- JSON schemaâ€“validated outputs
- Classification: type, priority, severity
- Edge case generation (security, concurrency, performance, accessibility)
- Coverage scoring to evaluate test completeness

### ğŸ“¤ Export Options
- JSON download
- CSV export for QA tools (Excel, TestRail, Jira)

### ğŸ–¥ Interfaces
- FastAPI backend
- Streamlit interactive UI

---

## ğŸ§  Why This Project?

Manual test case design is:
- time-consuming
- inconsistent
- prone to missing edge cases

This system automates requirement-to-test translation and ensures coverage across critical testing dimensions.

---

## ğŸ— Architecture
```

Requirement  
â†“  
Prompt Engineering  
â†“  
LLM (Gemini / extensible to Ollama)  
â†“  
JSON Extraction & Validation  
â†“  
Coverage Scoring  
â†“  
Export (JSON / CSV)  
â†“  
FastAPI & Streamlit UI

```
---

## ğŸ“‚ Project Structure
```

llm-testcase-generator/  
â”‚  
â”œâ”€â”€ app/  
â”‚ â”œâ”€â”€ main.py # FastAPI backend  
â”‚ â”œâ”€â”€ streamlit\_app.py # Streamlit UI  
â”‚ â”œâ”€â”€ llm\_client.py # LLM provider integration  
â”‚ â”œâ”€â”€ llm\_service.py # Retry & orchestration  
â”‚ â”œâ”€â”€ prompt.py # Prompt template  
â”‚ â”œâ”€â”€ schema.py # Pydantic schema  
â”‚ â”œâ”€â”€ validator.py # JSON extraction & validation  
â”‚ â”œâ”€â”€ coverage.py # Coverage scoring  
â”‚ â””â”€â”€ exporter.py # JSON & CSV export  
â”‚  
â”œâ”€â”€ examples/ # Demo dataset  
â”œâ”€â”€ exports/ # Generated files (ignored)  
â”œâ”€â”€ .env.example  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md

```
---

## â–¶ï¸ Run Locally

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/llm-testcase-generator.git
cd llm-testcase-generator
```

### 2ï¸âƒ£ Create virtual environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Set API key

Copy `.env.example` â†’ `.env`

```ini
GOOGLE_API_KEY=your_api_key_here
```

---

## ğŸš€ Run FastAPI

```bash
uvicorn app.main:app --reload
```

Open:  
ğŸ‘‰ http://127.0.0.1:8000/docs

---

## ğŸ–¥ Run Streamlit UI

```bash
streamlit run streamlit_app.py
```

---

## ğŸ§ª Example Input

```arduino
User can upload profile image with maximum size 2MB.
Supported formats: JPG and PNG.
```

---

## ğŸ“Š Example Output

The system generates:

-   Positive tests
    
-   Boundary conditions (2MB limit)
    
-   Security scenarios (XSS, path traversal)
    
-   Concurrency tests
    
-   Accessibility considerations
    
-   Coverage summary with missing categories
    

---

## ğŸ“ˆ Coverage Scoring

The system evaluates test completeness across:

-   Positive scenarios
    
-   Negative scenarios
    
-   Boundary conditions
    
-   Security tests
    
-   Performance tests
    
-   Concurrency tests
    
-   Accessibility
    

---

## ğŸ”® Future Enhancements

-   Multi-requirement parsing
    
-   Automation script generation (Selenium/Postman)
    
-   Ollama local model support
    
-   Prompt auto-improvement based on coverage gaps
    
-   Deployment on Streamlit Cloud
    

---

## ğŸ‘¨â€ğŸ’» Author

**Harsha Vardhan Nandineni**

Final-year Computer Science student specializing in:

-   Generative AI
    
-   LLM integration
    
-   QA automation systems
    
-   FastAPI backend development
    
![Python](https://img.shields.io/badge/Python-3.10-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-green)
![Streamlit](https://img.shields.io/badge/Streamlit-UI-red)
![LLM](https://img.shields.io/badge/LLM-Gemini-purple)

---